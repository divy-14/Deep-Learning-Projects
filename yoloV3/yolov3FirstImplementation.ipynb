{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")\n",
    "classes =[]\n",
    "\n",
    "# string = ' xoxo love xoxo   '\n",
    "# Leading whitepsace are removed\n",
    "# print(string.strip())\n",
    "\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes=[line.strip() for line in f.readlines()]\n",
    "    '''for lines in f.readlines():\n",
    "        classes.append(lines.strip())\n",
    "        print(\"hello\")'''\n",
    "#print(classes)   \n",
    "#print(len(classes)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = net.getLayerNames()\n",
    "#print(len(layer_names))\n",
    "output_layers =[]\n",
    "for i in net.getUnconnectedOutLayers():\n",
    "    #print(i)\n",
    "    output_layers.append(layer_names[i[0]-1]) #output layer for 3 strides present at index 200-1, 227-1, and 254-1 in orignal list\n",
    "#print(output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 416, 416)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread("")\n" #enter the name for your image file here,
    "img = cv2.resize(img,None,fx=0.4,fy=0.4)\n",
    "\n",
    "# for yolo we need blob of accurate dimension for each channel seperately\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img,0.00392,(416,416),(0,0,0),True,crop=False)\n",
    "#0.00392 is the scaling factor, True denotes that we are reversing the color scheme BGR to RGB\n",
    "print(blob.shape)\n",
    "\n",
    "for b in blob:\n",
    "    #print(b.shape) # -----> (3,416,416)\n",
    "    color =[\"red\",\"green\",\"blue\"]\n",
    "    count=0\n",
    "    for img_blob in b:\n",
    "        count = count+1\n",
    "        cv2.imshow(\"blob \"+color[count-1],img_blob)\n",
    "        \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "height,width,channel = img.shape\n",
    "net.setInput(blob)\n",
    "out = net.forward(output_layers) # all the info is present in this array\n",
    "#print(np.shape(out))\n",
    "#print(out) # the list out contains 3 arrays\n",
    "\n",
    "confidences =[]\n",
    "boxes =[]\n",
    "class_ids =[]\n",
    " \n",
    "\n",
    "for o in out:\n",
    "    #print(o.shape)\n",
    "    for detection in o:\n",
    "        #Each bounding box is represented by 6 \n",
    "        #numbers (𝑝𝑐,𝑏𝑥,𝑏𝑦,𝑏ℎ,𝑏𝑤,𝑐)(pc,bx,by,bh,bw,c).\n",
    "        #pc is the center coordinate\n",
    "        #If we expand c into an 80-dimensional vector, \n",
    "        #each bounding box is then represented by 85 numbers.\n",
    "        scores = detection[5:]\n",
    "        #print(detection[0],detection[1],detection[2],detection[3],detection[4])\n",
    "        #detection(84)==?\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        \n",
    "        if confidence>0.5:\n",
    "            # object detected\n",
    "            center_x = int(detection[0]*width)\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            #cv2.circle(img,(center_x,center_y),10,(0,255,0))\n",
    "           \n",
    "            # coordinates for rectangle\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append(float(confidence)) \n",
    "            class_ids.append(class_id)\n",
    "\n",
    "#objects_detected = len(boxes)\n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4) #the confidences provided to nms should be float not float32\n",
    "print(indexes)\n",
    "\n",
    "img_copy = img.copy()\n",
    "for i in indexes:\n",
    "    x,y,w,h = boxes[i[0]]\n",
    "    label = str(classes[class_ids[i[0]]])\n",
    "    cv2.rectangle(img_copy,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    cv2.putText(img_copy, label,(x,y-20),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),3) \n",
    "\n",
    "    \n",
    "cv2.imshow(\"frame\",img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
